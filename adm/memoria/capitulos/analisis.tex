\chapter{Herramientas e infraestructuras utilizadas}
\label{cap:analisis}

[Revisar]\\

En este capítulo se realiza un breve análisis de las distintas herramientas e infraestructuras usadas a lo largo del proyecto.


\section{Análisis de la herramienta de gestión de configuración}

Las herramientas de gestión de configuración tienen como objetivo llevar a un nodo a un cierto estado. Normalmente esto suele incluir la especificación de los recursos (ficheros, usuarios, paquetes instalados, etc.) que dicho nodo debería tener. Para cumplir esta misión se apoyan en dos conceptos básicos: convergencia e iteración. Estas herramientas tratan iteración tras iteración de acercar al nodo lo máximo posible al estado deseado. Es posible, por tanto, que el estado final no se alcance en una única ejecución, sino que sean necesarias varias ejecuciones. Aunque esto pueda contrastar con el funcionamiento habitual de los programas (sería sorprendente que sólo se abriera medio editor de texto), no es tan excepcional en este entorno: si tenemos que poner en marcha dos servicios, de los cuales uno de ellos depende del otro, hasta que el primero no esté funcionando no podrá hacerlo el segundo. Una sola ejecución de la herramienta no serviría para poner ambos servicios en marcha, sino que serían necesarias dos iteraciones como mínimo. \\

%Puppet, al igual que otras herramientas de configuración, trata de que los nodos converjan hacia un estado concreto, pero no garantiza que esto ocurra en una única ejecución. Es posible que sean necesarias varias ejecuciones de Puppet, aun cuando todo va bien, para alcanzar el estado deseado. Aunque esto pueda contrastar con la ejecución habitual de los programas, no es tan excepcional: si tenemos que poner en marcha dos servicios, de los cuales uno de ellos depende del otro, hasta que el primero no esté funcionando no podrá hacerlo el segundo. Una sola ejecución de Puppet no valdría para poner ambos servicios en marcha, sino que harían falta dos iteraciones como mínimo.

Puppet \cite{puppetlabs} es una herramienta de gestión de configuración que posee un lenguaje declarativo (ver Anexo \ref{anx:puppet-language}) mediante el cual se especifica la configuración de los sistemas. A través de este lenguaje se modelan los distintos elementos de configuración, que en la terminología de Puppet se llaman recursos. Mediante el uso de este lenguaje se indica en qué estado se quiere mantener el recurso y será tarea de Puppet el encargarse de que así sea. Cada recurso está compuesto de un tipo (el tipo de recurso que estamos gestionando), un título (el nombre del recurso) y una serie de atributos (los valores que especifican el estado del recurso). 

La agrupación de uno o más recursos en un fichero de texto da lugar a un manifiesto. En general, un manifiesto contiene la información necesaria para realizar la configuración de un nodo. Un usuario normal de Puppet creará manifiestos en los que especifique los recursos y su estado. Por ejemplo, para crear un fichero un usuario escribirá en un manifiesto algo similar a lo siguiente:

\begin{lstlisting}
file {'testfile':
  path    => '/tmp/testfile',
  ensure  => present,
  mode    => 0640,
  content => "I'm a test file.",
}
\end{lstlisting}

Los usuarios más avanzados de Puppet pueden crear sus propios tipos de recursos. Para que Puppet sepa cómo tratar con ese recurso deberá crear un proveedor. Esencialmente, el tipo se encarga de definir qué se puede hacer con un recurso y el proveedor se encarga de definir cómo hacerlo.

Cuando se tiene listo el manifiesto a Puppet se le da la orden de aplicarlo. Los pasos que sigue para aplicarlo son:

\begin{itemize}
\item Interpretar y compilar la configuración.
\item Comunicar la configuración compilada al nodo.
\item Aplicar la configuración en el nodo.
\item Enviar un informe con los resultados.
\end{itemize}


Normalmente Puppet se ejecuta de manera periódica mediante un planificador de trabajos (por ejemplo, cron). Cada cierto tiempo contactará con el nodo que debe ser administrado y volverá a repetir los pasos anteriores. Es decir, Puppet está continuamente intentando llevar al nodo al estado especificado en el manifiesto. Si entre una ejecución y otra algo cambiara en el nodo, Puppet se daría cuenta e intentaría llevar al nodo al estado que le corresponde. \\

Aunque Puppet tiene la capacidad de actuar sobre un nodo distinto al nodo desde el que se aplica el manifiesto, a lo largo de este proyecto las ejecuciones de Puppet siempre serán sobre el nodo que aplica el manifiesto, siempre serán locales. \\

Además de permitir la creación de tipos y proveedores para los usuarios más avanzados, Puppet tiene otros puntos de extensión. Uno de ellos es la API \emph{Faces} \cite{puppet-faces}, que permite crear subcomandos y acciones dentro de Puppet. Después de analizar esta API a fondo se vio que las opciones que ofrecía no permitían la integración del recurso distribuido dentro del modelo de Puppet. Como lo que interesaba era crear una abstracción del recurso distribuido esta opción se acabó descartando en favor de la creación de un tipo y un proveedor, que soluciona el problema de una manera más elegante.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Análisis de las infraestructuras de ejecución de trabajos distribuidos}

En esta sección se analizarán en profundidad las dos infraestructuras de ejecución de trabajos distribuidos usadas en este proyecto: AppScale y TORQUE


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Análisis de la infraestructura AppScale}

%%% Revisar
AppScale es una implementación \emph{open source} del App Engine de Google. Al igual que App Engine, AppScale permite alojar aplicaciones web; a diferencia de App Engine, las aplicaciones no serán alojadas en la infraestructura que Google posee, sino que serán alojadas en una infraestructura que el usuario posea. Además de permitir alojar aplicaciones web, AppScale también ofrece las APIs de MapReduce y Neptune. La API de MapReduce permite escribir aplicaciones que hagan uso del \emph{framework} MapReduce. La API de Neptune añade a App Engine la capacidad de usar los nodos de la infraestructura para ejecutar trabajos. Los trabajos más representativos que puede ejecutar son: de entrada, de salida y MPI, aunque también se pueden ejecutar trabajos de otro tipo. \\

AppScale trata de imitar de la manera más fiel los servicios que ofrece el App Engine de Google, tratatando de alcanzar el mayor grado de compatibilidad posible. Como la tecnología que Google usa para hacer esto posible permanece oculta al público, AppScale tiene que hacer uso de otras tecnologías existentes para ofrecer las mismas funciones. En la Figura \ref{figure:tecnologias-appscale} se puede ver toda la pila de tecnologías usadas en AppScale.

\begin{figure} [!htbp]
  \centering
  \includegraphics[width=13.5cm]{imagenes/AppScale_Stack.png}
  \caption{Tecnologías usadas por AppScale.}
\label{figure:tecnologias-appscale}
\end{figure}

Para permitir el alojamiento de aplicaciones web y la ejecución de trabajos una compleja infraestructura debe ponerse en marcha. Los distintos roles que un nodo puede desempeñar en una infraestructura de este tipo son los siguientes:

\begin{description}
\item[\texttt{Shadow}]: Comprueba el estado en el que se encuentran el resto de nodos.
\item[\texttt{Load balancer}]: Servicio web que lleva a los usuarios a las aplicaciones.
\item[\texttt{AppEngine}]: Aloja las aplicaciones web de los usuarios.
\item[\texttt{Database}]: Ejecuta los servicios necesarios para alojar a la base de datos elegida.
\item[\texttt{Login}]: Máquina desde la que se pueden hacer funciones administrativas.
\item[\texttt{Memcache}]: Proporciona soporte para almacenamiento en caché para las aplicaciones App Engine.
\item[\texttt{Zookeeper}]: Aloja los metadatos necesarios para hacer transacciones en las bases de datos.
\item[\texttt{Open}]: No ejecuta nada por defecto, pero está disponible en caso de que sea necesario.
\end{description}

Como muchos de estos roles suele desempeñarlos una máquina, se han creado unos roles agregados para facilitar el despliegue de la infraestructura. El rol \texttt{Controller} está compuesto por los roles Shadow, Load Balancer, Database, Login y Zookeeper; el rol \texttt{Servers} agrupa a los roles AppEngine, Database y Load Balancer; el rol \texttt{Master} está formado por los roles Shadow, Load Balancer y Zookeeper. Una especificación más detallada de los roles puede encontrarse en el Anexo \ref{anx:appscale-roles}.

AppScale contempla la posibilidad de dos tipos de despliegue: por defecto y personalizado. En el despliegue por defecto un nodo sólo puede ser o bien \texttt{Controller} o bien \texttt{Servers}. En el despliegue personalizado el usuario es libre de especificar los roles de manera más precisa. \\

Una vez puesta en marcha la infraestructura de AppScale, servirá tanto para alojar las aplicaciones web que el usuario despliegue como para ejecutar trabajos. Para desplegar las aplicaciones web hay que hacer uso de las AppScale Tools, un conjunto de herramientas que permiten, entre otras cosas, iniciar y terminar instancias, desplegar aplicaciones y eliminar aplicaciones. Para ejecutar trabajos hay que servirse de la API de Neptune, que no es tan sencilla. En general esto se consigue mediante tres pasos: en el primero se le indica el código fuente que se quiere subir a la infraestructura; en el segundo se le da la orden de ejecutar el trabajo; en el tercero se le piden los resultados de la ejecución. Cada uno de estos pasos debe indicarse, mediante un lenguaje específico de dominio, en un fichero que luego se interpretará con el programa Neptune. En el caso de un trabajo MPI, podemos definir, además del código a ejecutar, el número de máquinas sobre las que ejecutar el código y el número de procesos que se usarán para el trabajo.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Análisis de la infraestructura TORQUE}

La otra infraestructura de ejecución de trabajos distribuidos que se ha elegido ha sido TORQUE, una de las infraestructuras clásicas en lo que a ejecución de trabajos se refiere. TORQUE permite a los usuarios la ejecución de trabajos \emph{batch} sobre un conjunto de nodos. Además de los nodos de computación necesarios para ejecutar los trabajos, una infraestructura de este tipo estará compuesta de un nodo maestro, que es el encargado de planificar la ejecución de los trabajos y de la gestión de los nodos de computación. \\

Una vez que la infraestructura está en funcionamiento los usuarios pueden mandar sus trabajos al nodo maestro. Éste, valiéndose de un planificador (en su versión más simple es una cola FIFO), decidirá a cuál de los nodos de computación le enviará el trabajo. El nodo de computación que reciba el trabajo será el encargado de ejecutarlo y de enviar los resultados de vuelta al nodo maestro una vez terminada la ejecución. \\

%Además de contar con un planificador básico, TORQUE permite la integración con otros planificadores como Maui Cluster Scheduler o Moab Workload Manager para mejorar tanto la planificación de trabajos como la administración del \emph{cluster}.

Además de contar con un planificador básico, TORQUE permite la integración con otros planificadores tanto comerciales como \emph{open source} para mejorar la planificación de trabajos y la administración de los nodos del \emph{cluster}.

\chapter{Introducción}
\label{cap:introduccion}


\section{Estado de la técnica}

Durante los últimos años la computación en la nube ha ido ganando importancia de manera progresiva. La capacidad de usar la computación como un servicio permite a los usuarios finales de una aplicación acceder a ésta a través de un navegador web, una aplicación móvil o un cliente de escritorio mientras que la lógica de la aplicación y los datos se encuentran en servidores situados en una localización remota. Las aplicaciones en la nube tratan de proporcionar al usuario el mismo servicio y rendimiento que las aplicaciones instaladas localmente en su ordenador.\\

A lo largo de este proyecto se verán tres ejemplos de infraestructuras distribuidas.
La primera de ellas es la infraestrucutra de ejecución de trabajos. Este tipo de infraestructuras está especializada en la ejecución de grandes cargas de trabajo paralelizable e intensivo en computación. Son por lo tanto idóneas para ser usadas en la computación de altas prestaciones. Dentro de esta infraestructura distribuida los ejemplos más claros que podemos encontrar son Condor y Torque.

La segunda infraestructura será la de servicios web en tres capas. Este tipo de infraestructuras tiene tres niveles claramente diferenciados: balanceo o distribución de carga, servidor web y base de datos. El primer nivel de esta arquitectura es el encargado de distribuir la carga (las peticiones web) a los elementos del segundo nivel. Éstos procesarán las peticiones web y para ello puede que tengan que consultar o modificar ciertos datos. Los datos de la aplicación se encuentran en el tercer nivel, y  por consiguiente, cada vez que uno de los elementos del segundo nivel necesite leer información de la base de datos o modificarla, accederá a este tercer nivel. En esta infraestructura no hay un ejemplo claro, pero cualquier página web profesional de hoy en día se sustenta en una arquitectura similar a ésta.

La tercera y última es AppScale, una implementación \emph{open source} del App Engine de Google. App Engine permite alojar tu aplicación web en la infraestructura que Google posee. AppScale añade a App Engine la capacidad de usar los nodos de la infraestructura para ejecutar trabajos. Los trabajos más representativos que puede ejecutar son: de entrada, de salida, MPI, R, UPC y X10. El trabajo de entrada sirve para subir el código a la infraestructura, el de salida para recoger los resultados obtenidos y el resto para ejecutar el trabajo propiamente dicho, que será de uno de los tipos anteriores. Como se puede suponer, una infraestructura de estas características no es precisamente sencilla, por lo que ...\\

De igual manera, las herramientas de administración de sistemas (o herramientas de gestión de configuración) también han experimentado un considerable avance. Con entornos cada vez más heterogéneos y complejos la administración de sistemas de manera manual ya no es una opción. Entre todo el conjunto de  herramientas destacan de manera especial Puppet y CFEngine. Puppet es una herramienta de gestión de configuración basada en un lenguaje  declarativo: el usuario especifica qué estado debe alcanzarse y Puppet se encarga de hacerlo. CFEngine permite al usuario un control más fino de cómo se hacen las cosas, ganando velocidad a costa de perder elementos de más alto nivel.\\

Sin embargo, estas herramientas de gestión de la configuración carecen de la funcionalidad requerida para administrar infraestructuras distribuidas.\\

Si tomamos la administración de un cloud como la administración de las MV que forman los nodos del cloud nos damos cuenta de que la administración es puramente software.\\

\section{Contexto del proyecto}

Para la realización de este proyecto de fin de carrera se ha hecho uso del laboratorio 1.03b de investigación que el Departamento de Informática e Ingeniería de Sistemas posee en la Escuela de Ingeniería y Arquitectura de la Universidad de Zaragoza.

\section{Objetivos}

El objetivo de este proyecto es proporcionar una herramienta que facilite la puesta en marcha de infraestructuras distribuidas y su posterior mantenimiento. Las tareas principales en las que se puede dividir este proyecto son:

\begin{enumerate}
\item Estudio de algunas de las infraestructuras distribuidas existentes profundizando en la parte relativa a la ejecución de trabajos distribuidos.
\item Análisis de las herramientas de administración de virtualización \emph{hardware}.
\item Investigación de las herramientas de gestión de configuración existentes más relevantes y elección de aquella que mayor facilidad de integración y uso proporcione.
\item Extensión de la herramienta de gestión de configuración para que soporte la puesta en marcha y el mantenimiento de un sistema de ejecución de trabajos distribuidos.
\end{enumerate}

\section{Organización de la memoria}

El resto de este documento queda organizado de la siguiente manera:
\begin{description}
\item[Capítulo \ref{cap:trabajo}] Trabajo realizado.
\item[Capítulo \ref{cap:conclusiones}] Conclusiones.
\end{description}


\section{Agradecimientos}

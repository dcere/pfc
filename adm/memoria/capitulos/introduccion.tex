\chapter{Introducción}
\label{cap:introduccion}


La computación en la nube es un nuevo paradigma que pretende transformar la computación en un servicio. Durante estos últimos años la computación en la nube ha ido ganando importancia de manera progresiva, ya que la posibilidad de usar la computación como un servicio permite a los usuarios de una aplicación acceder a ésta a través de un navegador web, una aplicación móvil o un cliente de escritorio, mientras que la lógica de la aplicación y los datos se encuentran en servidores situados en una localización remota. Esta facilidad de acceso a la aplicación sin necesitar de un profundo conocimento de la infraestructura es la que, por ejemplo, brinda a las empresas la posibilidad de ofrecer servicios web sin tener que hacer una gran inversión inicial en infraestructura propia. Las aplicaciones alojadas en la nube tratan de proporcionar al usuario el mismo servicio y rendimiento que las aplicaciones instaladas localmente en su ordenador.\\

A lo largo de los últimos años las herramientas de gestión de configuración (o herramientas de administración de sistemas) también han experimentado un considerable avance: con entornos cada vez más heterogéneos y complejos la administración de estos sistemas de forma manual ya no es una opción. Entre todo el conjunto de herramientas de gestión de configuración destacan de manera especial Puppet \cite{puppetlabs} y CFEngine \cite{cfengine}. Puppet es una herramienta basada en un lenguaje declarativo: el usuario especifica qué estado debe alcanzarse y Puppet se encarga de hacerlo. CFEngine, también con un lenguaje declarativo, permite al usuario un control más detallado de cómo se hacen las cosas, mejorando el rendimiento a costa de perder abstracciones de más alto nivel.

Sin embargo, estas herramientas de gestión de la configuración carecen de la funcionalidad requerida para administrar infraestructuras distribuidas. Son capaces de asegurar que cada uno de los nodos se comporta de acuerdo a la configuración que le ha sido asignada pero no son capaces de administrar una infraestructura distribuida como una entidad propia. Si tomamos la administración de un \emph{cloud} como la administración de las máquinas virtuales que forman los nodos del mismo nos damos cuenta de que la administración es puramente \emph{software}. Únicamente tenemos que asegurarnos de que para cada nodo de la infraestructura distribuida hay una máquina virtual que está cumpliendo con su función.\\

Teniendo en cuenta el considerable avance de la computación en la nube, parece claro que el siguiente paso de las herramientas de gestión de configuración debería ir encaminado a la gestión de la nube. Para demostrar una posible manera en la que esto se podría lograr, en este proyecto se ha tomado una de esas herramientas de gestión de la configuración y se ha extendido su funcionalidad añadiéndole la posibilidad de gestionar infraestructuras distribuidas. La modificación realizada se ha validado usando tres ejemplos de infraestructuras distribuidas: las dos primeras de ejecución de trabajos y la última es una infraestructura web de tres niveles que demuestra que la solución obtenida no es únicamente válida para las infraestructuras de ejecución de trabajos.

La primera de estas infraestructuras es AppScale \cite{appscale}, una implementación de código abierto del App Engine de Google \cite{appengine}. App Engine permite alojar aplicaciones web en la infraestructura que Google posee. Además del alojamiento de aplicaciones web que ofrece App Engine, AppScale también ofrece las APIs de EC2 \cite{appscale-ec2}, MapReduce \cite{appscale-mapreduce} y Neptune \cite{appscale-neptune}. El API de EC2 añade a las aplicaciones la capacidad de interactuar con máquinas alojadas en Amazon EC2 \cite{amazon-ec2}. El API de MapReduce permite escribir aplicaciones que hagan uso del \emph{framework} MapReduce. La última API, Neptune, añade a AppScale la capacidad de usar los nodos de la infraestructura para ejecutar trabajos. Los trabajos más representativos que puede ejecutar son: de entrada, de salida y MPI \footnote[1]{MPI (del inglés \emph{Message Passing Interface}, Interfaz de Paso de Mensajes) es un estándar que define la sintaxis y la semántica de las funciones de una biblioteca de paso de mensajes diseñada para ser usada en programas que exploten la existencia de múltiples procesadores.}. El trabajo de entrada sirve para subir ficheros (generalmente el código que se ejecutará) a la infraestructura, el de salida para traer ficheros (generalmente los resultados obtenidos después de la ejecución) y el de MPI para ejecutar un trabajo MPI.

La segunda es TORQUE \cite{Staples:2006:TRM:1188455.1188464, torque}, una infraestructura de ejecución de trabajos distribuidos. Este tipo de infraestructuras están especializadas en la ejecución de grandes cargas de trabajo paralelizable e intensivo en computación. Son por lo tanto idóneas para ser usadas en la computación de altas prestaciones.

La tercera y última infraestructura es la de servicios web en tres capas, así denominada porque tiene tres niveles claramente diferenciados: balanceo o distribución de carga, servidor web y base de datos. El balanceador de carga es el encargado de distribuir las peticiones web a los servidores web que se encuentran en el segundo nivel de la infraestructura. Éstos procesarán las peticiones web y para responder a los clientes puede que tengan que consultar o modificar ciertos datos. Los datos de la aplicación se encuentran en la base de datos, el tercer nivel de la estructura, y por consiguiente, cada vez que uno de los elementos del segundo nivel necesite leer información o modificarla, accederá a este nivel. Para esta infraestructura no se puede elegir un ejemplo que destaque sobre los demás porque es tan común que cualquier página web profesional de hoy en día se sustenta en una infraestructura similar a ésta.\\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Contexto del proyecto}

Para la realización de este proyecto de fin de carrera se ha hecho uso del laboratorio 1.03b de investigación que el Departamento de Informática e Ingeniería de Sistemas posee en la Escuela de Ingeniería y Arquitectura de la Universidad de Zaragoza. Los ordenadores que forman este laboratorio poseen procesadores con soporte de virtualización, lo que permite la creación de diversas máquinas virtuales. La creación de los distintos tipos de \emph{cloud} que representan cada una de las infraestructuras distribuidas se ha llevado a cabo a través de máquinas virtuales alojadas en distintos ordenadores del laboratorio.\\

En este laboratorio se ha comprobado la validez de la extensión introducida en la herramienta de gestión de configuraciones Puppet para administración de infraestructuras distribuidas que se ha desarrollado a lo largo de este proyecto de fin de carrera.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Objetivos}

El objetivo de este proyecto es proporcionar una herramienta que facilite la puesta en marcha de infraestructuras distribuidas y su posterior mantenimiento. Las tareas principales en las que se puede dividir este proyecto son:

\begin{enumerate}
\item Modelado de un recurso distribuido en la herramienta de gestión de la configuración Puppet, proporcionando facilidades a los usuarios que quieran definir infraestructuras distribuidas.
\item Definición de una metodología de diseño e implementación de un recurso sistema distribuido.
\item Aplicación de dicha metodología en las infraestructuras distribuidas AppScale, TORQUE y servicios web en tres niveles.
\item Validación de la extensión desarrollada en la herramienta de gestión de configuración para la puesta en marcha y el mantenimiento de dichas infraestructuras.
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Trabajos previos}

Desde un primer momento se decidió trabajar con la herramienta de gestión de la configuración Puppet para la realización de este proyecto. La otra alternativa posible era CFEngine, pero a diferencia de ésta, Puppet posee un nivel mayor de abstracción que permite un mejor modelado de los recursos de un sistema. Además, el hecho de que Puppet esté programado en Ruby hace que sea más fácil trabajar y realizar abstracciones de alto nivel en él que en CFEngine, que está programado en el lenguaje C.

También se decidió desde el principio trabajar con la infraestructura de ejecución de trabajos que proporciona AppScale. AppScale combina la capacidad de ejecutar trabajos con el alojamiento de aplicaciones web. Esta dualidad la convierte en una infraestructura muy interesante para trabajar con ella.

La infraestructura de ejecución de trabajos TORQUE también se eligió desde el inicio. La infraestructura de servicios web en tres niveles se incluyó para cerciorarnos de que la solución aportada era lo suficientemente genérica para cualquier infraestructura distribuida, y no se centraba únicamente en las de ejecución de trabajos.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tecnologías utilizadas}


Para la elaboración de este proyecto se ha hecho uso de las siguientes tecnologías: KVM, QEMU, libvirt y virsh para el soporte y la gestión de las máquinas virtuales; Puppet como herramienta de configuración automática; Ruby como lenguaje de programación para la extensión de Puppet; AppScale y TORQUE como infraestructuras de ejecución de trabajos distribuidos en las que validar la extensión; Nginx, WEBrick y MySQL como balanceador de carga, servidor web y base de datos para la infraestructura web de tres niveles en la que se valida la extensión; Shell como lenguaje de programación de los \emph{scripts} de configuración de las máquinas virtuales; Sistema operativo Debian para las máquinas del laboratorio y Ubuntu para las máquinas virtuales; \LaTeX{} \cite{manual:latex} para la redacción de esta memoria y Dia para la confección de los diagramas que aparecen en esta memoria. \\

De todas las tecnologías aquí expuestas, Puppet, la herramienta de gestión de la configuración, es la tecnología más importante. El resto de herramientas utilizadas en este proyecto se explican con más detalle en sus respectivas secciones.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Organización de la memoria}


El resto de este documento queda organizado de la siguiente manera: el capítulo \ref{cap:herramientas} describe las herramientas e infraestructuras utilizadas; el capítulo \ref{cap:modelado} indica cómo se ha realizado el modelado de recursos distribuidos con Puppet; el capítulo \ref{cap:metodologia} introduce la metodología de diseño e implementación de recursos distribuidos; el capítulo \ref{cap:disenyo} muestra como aplicar dicha metodología a la creación de recursos distribuidos; el capítulo \ref{cap:validacion} valida la solución planteada y el capítulo \ref{cap:conclusiones} presenta las conclusiones obtenidas e indica las posibilidades de trabajo futuro.

Además consta de una serie de anexos organizados de esta manera: el anexo \ref{anx:gestion} muestra la gestión del proyecto; el anexo \ref{anx:ejemplo} muestra un ejemplo de uso; el anexo \ref{anx:puppet-language} amplía el lenguaje declarativo de Puppet; el anexo \ref{anx:appscale} profundiza en la infraestructura AppScale; el anexo \ref{anx:instalacion} muestra el proceso de instalación de algunas de las tecnologías usadas a lo largo de este proyecto y el anexo \ref{anx:codigo} contiene el código fuente de la solución planteada.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Agradecimientos}


Quisiera agradecer en primer lugar a Javier Celaya y a Unai Arronategui por la oportunidad que me han dado de hacer este proyecto, por su guía y por su infinita paciencia durante el mismo. \\

A los amigos de aquí y a los de allá, a los de la carrera y a los de fuera, por hacer esto mucho más llevadero. \\

A mis padres, por trabajar durante toda su vida para que hoy pueda estar donde estoy y por su apoyo a lo largo de toda la carrera. \\

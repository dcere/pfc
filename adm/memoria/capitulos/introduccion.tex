\chapter{Introducción}
\label{cap:introduccion}

[Revisar]\\

La computación en la nube es un nuevo paradigma que pretende transformar la computación en un servicio. Durante estos últimos años la computación en la nube ha ido ganando importancia de manera progresiva ya que la posibilidad de usar la computación como un servicio permite a los usuarios de una aplicación acceder a ésta a través de un navegador web, una aplicación móvil o un cliente de escritorio mientras que la lógica de la aplicación y los datos se encuentran en servidores situados en una localización remota. Esta facilidad de acceso a la aplicación sin necesitar de un profundo conocimento de la infraestructura es la que, por ejemplo, brinda a las empresas la posibilidad de ofrecer servicios web sin tener que hacer una gran inversión inicial en infraestructura propia. Las aplicaciones alojadas en la nube tratan de proporcionar al usuario el mismo servicio y rendimiento que las aplicaciones instaladas localmente en su ordenador.\\

A lo largo de este proyecto se han usado tres ejemplos de infraestructuras distribuidas. La primera de ellas es la infraestructura de ejecución de trabajos. Este tipo de infraestructuras está especializada en la ejecución de grandes cargas de trabajo paralelizable e intensivo en computación. Son por lo tanto idóneas para ser usadas en la computación de altas prestaciones. Dentro de esta infraestructura distribuida los ejemplos más claros que podemos encontrar son Condor y Torque.

La segunda infraestructura es la de servicios web en tres capas. Este tipo de infraestructura tiene tres niveles claramente diferenciados: balanceo o distribución de carga, servidor web y base de datos. El balanceador de carga es el encargado de distribuir las peticiones web a los servidores web que se encuentran en el segundo nivel de la infraestructura. Éstos procesarán las peticiones web y para responder a los clientes puede que tengan que consultar o modificar ciertos datos. Los datos de la aplicación se encuentran en el tercer nivel de la estructura, y por consiguiente, cada vez que uno de los elementos del segundo nivel necesite leer información de la base de datos o modificarla, accederá a este nivel. En esta infraestructura no hay un ejemplo de uso que destaque sobre los demás, pero es tan común que cualquier página web profesional de hoy en día se sustenta en una infraestructura similar a ésta.

La tercera y última es AppScale, una implementación \emph{open source} del App Engine de Google. App Engine permite alojar aplicaciones web en la infraestructura que Google posee. Además de presentar esta funcionalidad AppScale también ofrece las APIs de EC2, MapReduce y Neptune. La API de EC2 añade a las aplicaciones la capacidad de interactuar con máquinas alojadas en Amazon EC2. La API de MapReduce permite escribir aplicaciones que hagan uso del \emph{framework} (o paradigma?) MapReduce. La última API, Neptune, añade a App Engine la capacidad de usar los nodos de la infraestructura para ejecutar trabajos. Los trabajos más representativos que puede ejecutar son: de entrada, de salida y MPI. El trabajo de entrada sirve para subir ficheros (generalmente el código que se ejecutará) a la infraestructura, el de salida para traer ficheros (generalmente los resultados obtenidos después de la ejecución) y el de MPI para ejecutar un trabajo MPI.

La infraestructura necesaria para dar soporte a todas estas APIs ya no es tan sencilla como en los dos casos anteriores. De hecho, las anteriores infraestructuras estarían contenidas en ésta. Hay dos maneras de definir la infraestructura de AppScale. En la primera de ellas se define un despliegue por defecto, en el que un nodo toma el rol de \emph{controller} y el resto de nodos toman el rol de \emph{servers}. El nodo \emph{controller} es el que carga con la responsabilidad de la coordinación y los nodos \emph{servers} son los que llevan cabo la mayor parte del trabajo. La segunda manera de definir la infraestructura es hacerlo a través de un despliegue personalizado. En este despliegue podemos definir con más precisión los roles que queremos que desempeñe un nodo. Entre todos los posibles roles que AppScale ofrece, los más interesantes desde nuestro punto de vista son: \emph{master}, \emph{appengine}, \emph{database}, \emph{login} y \emph{open}.\\

A lo largo de los últimos años las herramientas de administración de sistemas (o herramientas de gestión de configuración) también han experimentado un considerable avance: con entornos cada vez más heterogéneos y complejos la administración de sistemas complejos de manera manual ya no es una opción. Entre todo el conjunto de herramientas destacan de manera especial Puppet y CFEngine. Puppet es una herramienta de gestión de configuración basada en un lenguaje declarativo: el usuario especifica qué estado debe alcanzarse y Puppet se encarga de hacerlo. CFEngine, también con un lenguaje declarativo, permite al usuario un control más detallado de cómo se hacen las cosas, mejorando el rendimiento a costa de perder abstracciones de más alto nivel.

Sin embargo, estas herramientas de gestión de la configuración carecen de la funcionalidad requerida para administrar infraestructuras distribuidas. Son capaces de asegurar que cada uno de los nodos se comporta de acuerdo a la configuración que le ha sido asignada pero no son capaces de administrar una infraestructura distribuida como una entidad propia. Si tomamos la administración de un \emph{cloud} como la administración de las máquinas virtuales que forman los nodos del mismo nos damos cuenta de que la administración es puramente \emph{software}. Únicamente tenemos que asegurarnos de que para cada nodo de la infraestructura distribuida hay una máquina virtual que está cumpliendo con su función.\\


\section{Contexto del proyecto}

Para la realización de este proyecto de fin de carrera se ha hecho uso del laboratorio 1.03b de investigación que el Departamento de Informática e Ingeniería de Sistemas posee en la Escuela de Ingeniería y Arquitectura de la Universidad de Zaragoza. Los ordenadores que forman este laboratorio poseen procesadores con soporte de virtualización, lo que permite la creación de diversas máquinas virtuales. La creación de los distintos tipos de cloud que representan cada una de las infraestructuras distribuidas se ha llevado a cabo a través de máquinas virtuales alojadas en distintos ordenadores del laboratorio.\\

En este laboratorio se ha comprobado la validez de la extensión introducida en la herramienta de gestión de configuraciones Puppet para administración de infraestructuras distribuidas que se ha desarrollado a lo largo de este proyecto de fin de carrera.


\section{Objetivos}

El objetivo de este proyecto es proporcionar una herramienta que facilite la puesta en marcha de infraestructuras distribuidas y su posterior mantenimiento. Las tareas principales en las que se puede dividir este proyecto son:

% TODO Comprobar que están en el mismo orden que el capítulo Estudio de las herramientas e infraestructuras.
\begin{enumerate}
\item Análisis de las herramientas de administración de virtualización \emph{hardware}.
\item Estudio de algunas de las infraestructuras distribuidas existentes profundizando en la parte relativa a la ejecución de trabajos distribuidos.
\item Investigación de las herramientas de gestión de configuración existentes más relevantes y elección de aquella que mayor facilidad de integración y uso proporcione.
\item Extensión de la herramienta de gestión de configuración para que soporte la puesta en marcha y el mantenimiento de un sistema de ejecución de trabajos distribuidos.
\end{enumerate}


\section{Trabajos previos}

La modificación que se ha hecho de la herramienta de configuración Puppet puede considerarse como un concepto novedoso en el campo de las herramientas de configuración. El funcionamiento habitual de este tipo de herramientas consiste en la administración de los recursos de un nodo; el concepto de la administración de un recurso distribuido entre varios nodos no se ha introducido de momento en este tipo de herramientas.


\section{Tecnología utilizada}

Para la elaboración de este proyecto se ha hecho uso de las siguientes tecnologías:
\begin{itemize}
\item KVM, QEMU, libvirt y virsh para el soporte y la gestión de las máquinas virtuales.
\item Ruby como lenguaje de programación para la extensión de Puppet.
\item Shell como lenguaje de programación de los \emph{scripts} de configuración de las máquinas virtuales.
\item Sistema operativo Debian para las máquinas del laboratorio y Ubuntu para las máquinas virtuales.
\item \LaTeX{} \cite{manual:latex} para la redacción de esta memoria.
\end{itemize}


\section{Organización de la memoria}

El resto de este documento queda organizado de la siguiente manera:
\begin{description}
\item[Capítulo \ref{cap:estudio}] Estudio de las herramientas e infraestructuras disponibles.
\item[Capítulo \ref{cap:modelado}] Extensión de Puppet para gestión de infraestructuras distribuidas.
\item[Capítulo \ref{cap:disenyo}] Diseño de recursos distribuidos específicos.
\item[Capítulo \ref{cap:validacion}] Validación de la solución planteada.
\item[Capítulo \ref{cap:conclusiones}] Conclusiones.
\end{description}


\section{Agradecimientos}

Agradecimientos
